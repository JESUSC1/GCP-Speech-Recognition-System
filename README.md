<a href="https://jupyter.org">
    <img src="https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white" alt="Jupyter Notebook" width="100" height="20">
</a>

<a href="https://www.python.org">
    <img src="https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54" alt="Python" width="100" height="20">
</a>

<a href="https://cloud.google.com">
    <img src="https://img.shields.io/badge/GoogleCloud-%234285F4.svg?style=for-the-badge&logo=google-cloud&logoColor=white" alt="Google Cloud" width="100" height="20">
</a>

<a href="https://www.apache.org">
    <img src="https://img.shields.io/badge/apache-%23D42029.svg?style=for-the-badge&logo=apache&logoColor=white" alt="Apache" width="100" height="20">
</a>

<a href="https://mybinder.org/v2/gh/JESUSC1/Speech-Recognition-Exercise.git/HEAD">
  <img src="https://mybinder.org/badge_logo.svg" alt="Binder" width="100" height="20">
</a>
</p>

<p><b>Speech-Recognition-Exercise:</b></p>

<p>The purpose of this project is to build a data pipeline to perform speech recognition and analysis by utilizing the SpeechRecognition library in Python and Google Cloud Speech-to-Text API. Note, for better interactivity with the Jupyter Notebook (Speech_Recognition_Exercise.ipynb) please launch binder by clicking on the respective badge.</p>

<p>The project is divided into two parts:</p>
<ol>
  <li><b>Training a speech recognition model:</b> This part of the project uses the SpeechRecognition library to train a speech recognition model on a dataset of audio recordings. The model is then saved to a file so that it can be used for inference.</li>
    
  <li><b>Performing speech recognition:</b> This part of the project uses the Google Cloud Speech-to-Text API to perform speech recognition on a live audio stream. The results of the speech recognition are then displayed to the user.</li>
</ol>

<p>Python Version: 3.10.9 | Google Cloud Speech: 2.20.0 | Jupyter Lab 3.0</p>

